import csv
import os
from os.path import join, isfile
import time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import theano
from keras.models import Sequential
from keras.layers.core import Dense, Activation, Flatten, Merge
from keras.layers.normalization import BatchNormalization
from keras.optimizers import SGD
from keras.layers.convolutional import Convolution1D
from keras.layers.pooling import MaxPooling1D
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from keras.utils.np_utils import to_categorical

from embedding import string_embedding
from dataClean import merge_csv

def history_logging(model_fit):
    '''
    Input: a keras model.fit history object
    Output: a csv file containing the history of fitting
    '''
    header = ['loss', 'acc', 'val_loss', 'val_acc']
    data = zip(model_fit.history['loss'], model_fit.history['acc'],
               model_fit.history['val_loss'], model_fit.history['val_acc'])

    directory = os.path.basename(os.getcwd())
    filename = 'fitlog_{0}.csv'.format(directory)
    print('Writing fit history to csv...')
    with open(filename, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(header)
        writer.writerows(data)


def generate_embedding(dataframe):
    '''
    Return a 3d array with shape (n, 100, 8) for training
    '''
    vsdt = dataframe['File VSDT'].str.replace('[', '').str.replace(']', '')
    vsdt = vsdt.str.split('_', 1).apply(lambda x: x[1].lower())
    filename_concate = vsdt + dataframe['FileFullPath']
    name_vector = filename_concate.apply(lambda x: string_embedding(x, clip=100))
    # name_vector = np.array([i for i in name_vector])
    return name_vector


class TrainModel(object):
    '''
    Handle model training
    '''

    folder = 'TotalFileSubmission_YangHu'
    path = join(os.getcwd(), folder, 'test')
    dataframe = merge_csv(path)
    name_vector = generate_embedding(dataframe)
    result = dataframe['Malware Result'].astype('category').cat.codes

    # Split data into: Training, Testing, Validating
    split = 0.2     # Ration of tests sample verses training samples
    seed = 42   # random state of train_test_split, for better debugging

    # Hyper Parameters
    learning_rate = 0.08
    learning_decay = learning_rate / 32
    bn_eps = 1
    early_stop = EarlyStopping(monitor='val_loss', patience=2)
    batch_size = 128
    epoch = 2

    # Model Structure
    md1 = Sequential()
    md2 = Sequential()
    md3 = Sequential()
    md4 = Sequential()
    md1.add(Convolution1D(50, 1, border_mode='same', input_shape=(100, 8)))
    md2.add(Convolution1D(50, 3, border_mode='same', input_shape=(100, 8)))
    md3.add(Convolution1D(75, 5, border_mode='same', input_shape=(100, 8)))
    md4.add(Convolution1D(75, 7, border_mode='same', input_shape=(100, 8)))

    model = Sequential()
    model.add(Merge([md1, md2, md3, md4], mode='concat', concat_axis=-1))
    model.add(BatchNormalization(epsilon=bn_eps))
    model.add(MaxPooling1D())
    model.add(Flatten())
    model.add(Dense(4))
    model.add(Activation('softmax'))

    sgd = SGD(lr=learning_rate, decay=learning_decay, momentum=0.9, nesterov=True)
    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])
    # print(model.summary())
    x_train, x_test, y_train, y_test = train_test_split(name_vector,
                                                        result,
                                                        test_size=split,
                                                        random_state=seed)
    x_train = np.array([i for i in x_train])
    x_test = np.array([i for i in x_test])
    y_train = to_categorical(y_train)
    y_test = to_categorical(y_test)
    print('Start training model...')
    data = [x_train, x_train, x_train, x_train]
    fit_log = model.fit(data, y_train,
                        batch_size=batch_size,
                        nb_epoch=epoch,
                        verbose=1, validation_split=0.4,
                        callbacks=[early_stop])
    history_logging(fit_log)

    def get_model(self,):
        return TrainModel.model

    def make_csv(self,):
        '''
        Add prediction column to original merged csv
        '''
        pass

    def export_model(self,):
        '''
        Return the final training keras model
        '''
        pass





def main():
    '''
    Run trainModel object
    '''
    test = TrainModel()
    test.get_model()



if __name__ == '__main__':
    main()
