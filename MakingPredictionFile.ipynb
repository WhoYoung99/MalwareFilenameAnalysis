{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import getcwd, listdir\n",
    "from os.path import join, isfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'TotalFileSubmission_YangHu'\n",
    "path = join(getcwd(), folder, '0206-0228')\n",
    "\n",
    "def merge_csv():\n",
    "    csv_list = [i for i in listdir(path) if i.startswith('TotalFileSubmission')]\n",
    "    \n",
    "    # Read all csv files into a pandas dataframe\n",
    "    # Encounter problem: '\\ufeff\"Neuron Source Type\"' got unwanted char at first header\n",
    "    df = pd.concat(pd.read_csv(join(path, i), encoding='utf-8') for i in csv_list)\n",
    "    column_names = df.columns.tolist()\n",
    "    column_names[0] = 'Neuron Source Type'\n",
    "    df.columns = column_names\n",
    "    ori_len = df.shape[0]\n",
    "\n",
    "    # Remove duplicated rows\n",
    "    df = df.dropna(subset=['FileFullPath'])\n",
    "    df = df.dropna(subset=['File VSDT'])\n",
    "    df = df.drop_duplicates(subset=['sha1','FileFullPath','File VSDT','Malware Result'], keep='last')\n",
    "    df = df[~df.FileFullPath.str.startswith('C:')]\n",
    "    df = df.reset_index(drop=True)\n",
    "    aft_len = df.shape[0]\n",
    "    \n",
    "    # Change label\n",
    "    row_indexer = df['Malware Result'] == 'SolProviding_Auto'\n",
    "    df.loc[row_indexer, 'Malware Result'] = 'Malicious'\n",
    "\n",
    "    # Merge all csv files into one\n",
    "    out_fn = 'merge.csv'\n",
    "    df.to_csv(join(path, out_fn))\n",
    "\n",
    "    print('Contains {}% of duplications'.format( (ori_len - aft_len)/ori_len*100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2683: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fn = '0206-0228_merge.csv'\n",
    "try:\n",
    "    df = pd.read_csv(join(path, fn), encoding='ISO-8859-1',index_col=0)\n",
    "except OSError:\n",
    "    merge_csv()\n",
    "    df = pd.read_csv(join(path, fn), encoding='ISO-8859-1',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "vsdt = df['File VSDT'].str.replace('[', '').str.replace(']','')\n",
    "vsdt = vsdt.str.split('_', 1).apply(lambda x: x[1].lower())\n",
    "filename_concate = vsdt + df['FileFullPath']\n",
    "print(type(filename_concate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_vector(string, clip):\n",
    "    '''\n",
    "    Turn each letter in a string into a list of ascii number\n",
    "    clip: truncate too long string to uniform length,\n",
    "          if string is shorter than clip number, padded with zeros\n",
    "    '''\n",
    "    string_to_int = np.array([ord(i) for i in string.lower()])\n",
    "    string_to_int.resize(clip)\n",
    "    return string_to_int\n",
    "\n",
    "def string_embedding(string, clip=100):\n",
    "    '''\n",
    "    Convert each lettter of the string to a 8-bit vector \n",
    "    Input: string\n",
    "    Output: 8-bit vector with shape(clip, 8)\n",
    "    '''\n",
    "    arr = string_vector(string, clip)\n",
    "    return np.array([tuple(map(int, tuple('{0:08b}'.format(i)))) for i in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_vector = filename_concate.apply(lambda x: string_embedding(x, clip=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = df['Malware Result'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal        73826\n",
       "Analyzing     37834\n",
       "NoDecision    30814\n",
       "Malicious     24078\n",
       "Name: Malware Result, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Malware Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/keras/engine/topology.py:1231: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(trainable=True, name=\"convolution1d_97\", kernel_initializer=\"glorot_uniform\", bias_constraint=None, use_bias=True, bias_regularizer=None, input_dtype=\"float32\", activation=\"linear\", kernel_regularizer=None, kernel_size=1, padding=\"same\", activity_regularizer=None, kernel_constraint=None, strides=1, input_shape=(None, Non..., filters=50, batch_input_shape=[None, 100...)`\n",
      "  return cls(**config)\n",
      "/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/keras/engine/topology.py:1231: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(trainable=True, name=\"convolution1d_98\", kernel_initializer=\"glorot_uniform\", bias_constraint=None, use_bias=True, bias_regularizer=None, input_dtype=\"float32\", activation=\"linear\", kernel_regularizer=None, kernel_size=3, padding=\"same\", activity_regularizer=None, kernel_constraint=None, strides=1, input_shape=(None, Non..., filters=50, batch_input_shape=[None, 100...)`\n",
      "  return cls(**config)\n",
      "/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/keras/engine/topology.py:1231: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(trainable=True, name=\"convolution1d_99\", kernel_initializer=\"glorot_uniform\", bias_constraint=None, use_bias=True, bias_regularizer=None, input_dtype=\"float32\", activation=\"linear\", kernel_regularizer=None, kernel_size=5, padding=\"same\", activity_regularizer=None, kernel_constraint=None, strides=1, input_shape=(None, Non..., filters=75, batch_input_shape=[None, 100...)`\n",
      "  return cls(**config)\n",
      "/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/keras/engine/topology.py:1231: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(trainable=True, name=\"convolution1d_100\", kernel_initializer=\"glorot_uniform\", bias_constraint=None, use_bias=True, bias_regularizer=None, input_dtype=\"float32\", activation=\"linear\", kernel_regularizer=None, kernel_size=7, padding=\"same\", activity_regularizer=None, kernel_constraint=None, strides=1, input_shape=(None, Non..., filters=75, batch_input_shape=[None, 100...)`\n",
      "  return cls(**config)\n",
      "/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/keras/engine/topology.py:1231: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n",
      "/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/keras/engine/topology.py:1231: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(trainable=True, epsilon=0.5, name=\"batchnormalization_14\", axis=-1, momentum=0.99, gamma_regularizer=None, beta_regularizer=None)`\n",
      "  return cls(**config)\n",
      "/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/keras/engine/topology.py:1231: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(trainable=True, name=\"maxpooling1d_19\", pool_size=2, padding=\"valid\", strides=2)`\n",
      "  return cls(**config)\n",
      "/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/keras/engine/topology.py:1231: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_regularizer=None, units=4, trainable=True, name=\"dense_19\", activity_regularizer=None, kernel_constraint=None, kernel_initializer=\"glorot_uniform\", bias_constraint=None, use_bias=True, bias_regularizer=None, input_dim=12500, activation=\"linear\")`\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 6 layers into a model with 2 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ce595c0c6aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.save('two_layer_dilated.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'four_layer_concate_BN05008.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# instantiate optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/whoyoung/anaconda3/envs/dnn/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2925\u001b[0m                          \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                          \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[1;32m   2928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m     \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 6 layers into a model with 2 layers."
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# model.save('two_layer_dilated.h5')\n",
    "model = load_model('four_layer_concate_BN05008.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166552,)\n",
      "(166552, 100, 8)\n"
     ]
    }
   ],
   "source": [
    "X_ver = name_vector\n",
    "print(X_ver.shape)\n",
    "X_ver = np.array([i for i in X_ver])\n",
    "print(X_ver.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epoch = 20\n",
    "\n",
    "pred = model.predict_classes([X_ver,X_ver,X_ver,X_ver], batch_size, verbose=2)\n",
    "mapping = dict(enumerate(df['Malware Result'].astype('category').cat.categories))\n",
    "pred = pd.Series(pred).map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Predict'] = pred\n",
    "df.to_csv(join(path, 'predict_3.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: four_layer_concate_BN\n",
    "# pred.value_counts()\n",
    "# Normal       132125\n",
    "# Malicious     34427\n",
    "# dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: two_layer_concate\n",
    "# pred.value_counts()\n",
    "# Normal       132254\n",
    "# Malicious     34298\n",
    "# dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yang_hu\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85991379310344829"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model: 2-layer without BN\n",
    "df = pd.read_csv(join(path, 'predict_1.csv'), encoding='ISO-8859-1',index_col=0)\n",
    "rows = df[(df['Malware Result'] == 'Malicious')|(df['Malware Result']=='Normal')]\n",
    "sum(rows['Malware Result'] == rows['Predict'])/len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86578689328321623"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model: 4-layer with BN\n",
    "rows = df[(df['Malware Result'] == 'Malicious')|(df['Malware Result']=='Normal')]\n",
    "sum(rows['Malware Result'] == rows['Predict'])/len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yang_hu\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87896306586043471"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model: 4-layer without BN eps=0.5 rate=0.08\n",
    "df = pd.read_csv(join(path, 'predict_3.csv'), encoding='ISO-8859-1',index_col=0)\n",
    "rows = df[(df['Malware Result'] == 'Malicious')|(df['Malware Result']=='Normal')]\n",
    "sum(rows['Malware Result'] == rows['Predict'])/len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
