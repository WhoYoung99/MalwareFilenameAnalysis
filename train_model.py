"""Handling data spliting, model training and result exporting
"""
# Python inherit
import csv
import os
import numpy as np
import time

# Third-party library
from keras.callbacks import EarlyStopping
from keras.utils.np_utils import to_categorical
from sklearn.model_selection import train_test_split

# Self-defined
from logger import logger, history_logging
from model import model
from embedding import embedding
from showtestacc import TestCallback

# Split data into: Training, Testing, Validating
SPLIT = 0.2     # Ratio of tests sample verses training samples
SEED = 42       # random state of train_test_split, for better debugging

# Hyper Parameters
LEARNING_RATE = 0.05
LEARNING_DECAY = LEARNING_RATE / 32
BN_EPS = 0.8
EARLY_STOP = EarlyStopping(monitor='val_acc', patience=3)
BATCH_SIZE = 128
EPOCH = 1

# Prepare training and testing samples
TRAIN_PATH = os.path.join(os.getcwd(), 'TrainingSamples')
logger.debug('Path for training sample: %s', TRAIN_PATH)
LABEL, FEATURE = embedding(TRAIN_PATH)
logger.debug('Training Size: %s', len(LABEL))
X_train, X_test, Y_train, Y_test = train_test_split(FEATURE,
                                                    LABEL,
                                                    test_size=SPLIT,
                                                    random_state=SEED)
X_train = np.array([i for i in X_train])
X_test = np.array([i for i in X_test])
Y_train = to_categorical(Y_train)
Y_test = to_categorical(Y_test)
logger.debug('training shape = %s', X_train.shape)

DATA = [X_train, X_train, X_train, X_train]

FIT_HISTORY = model.fit(DATA, Y_train,
                        batch_size=BATCH_SIZE,
                        epochs=EPOCH,
                        verbose=1,
                        validation_split=0.4,
                        # validation_data=(X_val, Y_val),
                        callbacks=[EARLY_STOP,])
history_logging(FIT_HISTORY)
loss, acc = model.evaluate([X_test, X_test, X_test, X_test],
                              Y_test,
                              verbose=1,
                              batch_size=32)
logger.info('Testing Acc: %s', acc)
logger.info('Testing Loss: %s', loss)

fname = 'DNN_{}.h5'.format(time.strftime('%Y%m%d-%H%M'))
model.save(fname)
logger.debug('Saving model as: %s', fname)
